<!doctype html>
<html lang="en"><head><meta charset="utf-8"><meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"><meta><title>Learning Frameworks in NLP (1/2) - Taeseung Hahn</title><link rel="manifest" href="/manifest.json"><meta name="application-name" content="Taeseung Hahn"><meta name="msapplication-TileImage" content="/img/favicon.png"><meta name="apple-mobile-web-app-capable" content="yes"><meta name="apple-mobile-web-app-title" content="Taeseung Hahn"><meta name="apple-mobile-web-app-status-bar-style" content="default"><meta name="description" content="IntroLIMA and KoLIMA"><meta property="og:type" content="blog"><meta property="og:title" content="Learning Frameworks in NLP (1/2)"><meta property="og:url" content="https://taes.me/LF-NLP-1/"><meta property="og:site_name" content="Taeseung Hahn"><meta property="og:description" content="IntroLIMA and KoLIMA"><meta property="og:locale" content="en_US"><meta property="og:image" content="https://taes.me/img/og_image.png"><meta property="article:published_time" content="2023-07-16T00:00:00.000Z"><meta property="article:modified_time" content="2023-07-16T13:59:31.625Z"><meta property="article:author" content="Taeseung Hahn"><meta property="article:tag" content="NLP"><meta property="twitter:card" content="summary"><meta property="twitter:image" content="/img/og_image.png"><script type="application/ld+json">{"@context":"https://schema.org","@type":"BlogPosting","mainEntityOfPage":{"@type":"WebPage","@id":"https://taes.me/LF-NLP-1/"},"headline":"Learning Frameworks in NLP (1/2)","image":["https://taes.me/img/og_image.png"],"datePublished":"2023-07-16T00:00:00.000Z","dateModified":"2023-07-16T13:59:31.625Z","author":{"@type":"Person","name":"Taeseung Hahn"},"publisher":{"@type":"Organization","name":"Taeseung Hahn","logo":{"@type":"ImageObject","url":"https://taes.me/img/ts_logo.png"}},"description":"IntroLIMA and KoLIMA"}</script><link rel="canonical" href="https://taes.me/LF-NLP-1/"><link rel="icon" href="/img/favicon.png"><link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.15.2/css/all.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/highlight.js@9.12.0/styles/atom-one-light.css"><link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=Ubuntu:wght@400;600&amp;family=Source+Code+Pro"><link rel="stylesheet" href="/css/default.css"><style>body>.footer,body>.navbar,body>.section{opacity:0}</style><!--!--><!--!--><!--!--><!--!--><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/cookieconsent@3.1.1/build/cookieconsent.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/lightgallery@1.10.0/dist/css/lightgallery.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/justifiedGallery@3.8.1/dist/css/justifiedGallery.min.css"><script src="https://www.googletagmanager.com/gtag/js?id=UA-194796796-1" async></script><script>window.dataLayer = window.dataLayer || [];
        function gtag(){dataLayer.push(arguments);}
        gtag('js', new Date());
    
        gtag('config', 'UA-194796796-1');</script><!--!--><!--!--><style>.pace{-webkit-pointer-events:none;pointer-events:none;-webkit-user-select:none;-moz-user-select:none;user-select:none}.pace-inactive{display:none}.pace .pace-progress{background:#3273dc;position:fixed;z-index:2000;top:0;right:100%;width:100%;height:2px}</style><script src="https://cdn.jsdelivr.net/npm/pace-js@1.2.4/pace.min.js"></script><!--!--><!--!--><meta name="naver-site-verification" content="45964f95ee60d3fb1ae3878a54b2ee03a83367b8"><!-- hexo injector head_end start --><script>
  (function () {
      function switchTab() {
          if (!location.hash) {
            return;
          }
          Array
              .from(document.querySelectorAll('.tab-content'))
              .forEach($tab => {
                  $tab.classList.add('is-hidden');
              });
          Array
              .from(document.querySelectorAll('.tabs li'))
              .forEach($tab => {
                  $tab.classList.remove('is-active');
              });
          const $activeTab = document.querySelector(location.hash);
          if ($activeTab) {
              $activeTab.classList.remove('is-hidden');
          }
          const $tabMenu = document.querySelector(`a[href="${location.hash}"]`);
          if ($tabMenu) {
              $tabMenu.parentElement.classList.add('is-active');
          }
      }
      switchTab();
      window.addEventListener('hashchange', switchTab, false);
  })();
  </script><!-- hexo injector head_end end --><meta name="generator" content="Hexo 6.2.0"></head><body class="is-2-column"><nav class="navbar navbar-main"><div class="container navbar-container"><div class="navbar-brand justify-content-center"><a class="navbar-item navbar-logo" href="/"><img src="/img/ts_logo.png" alt="Taeseung Hahn" height="28"></a></div><div class="navbar-menu"><div class="navbar-start"><a class="navbar-item" href="/">Home</a><a class="navbar-item" href="/archives">Archives</a><a class="navbar-item" href="/categories">Categories</a><a class="navbar-item" href="/tags">Tags</a><a class="navbar-item" href="/about">About</a></div><div class="navbar-end"><a class="navbar-item" target="_blank" rel="noopener" title="Find me on Linkedin!" href="https://www.linkedin.com/in/taeshahn/"><i class="fab fa-linkedin"></i></a><a class="navbar-item is-hidden-tablet catalogue" title="Catalogue" href="javascript:;"><i class="fas fa-list-ul"></i></a><a class="navbar-item search" title="Search" href="javascript:;"><i class="fas fa-search"></i></a></div></div></div></nav><section class="section"><div class="container"><div class="columns"><div class="column order-2 column-main is-9-tablet is-9-desktop is-9-widescreen"><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item">Posted&nbsp;<time dateTime="2023-07-16T00:00:00.000Z" title="7/16/2023, 12:00:00 AM">2023-07-16</time></span><span class="level-item"><a class="link-muted" href="/categories/NLP/">NLP</a></span><span class="level-item">16 minutes read (About 2443 words)</span></div></div><h1 class="title is-3 is-size-4-mobile">Learning Frameworks in NLP (1/2)</h1><div class="content"><h1 id="Intro"><a href="#Intro" class="headerlink" title="Intro"></a>Intro</h1><h2 id="LIMA-and-KoLIMA"><a href="#LIMA-and-KoLIMA" class="headerlink" title="LIMA and KoLIMA"></a>LIMA and KoLIMA</h2><p>최근에 KoLIMA라는 사이드 프로젝트를 하나 시작했습니다. <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2305.11206">LIMA: Less Is More for Alignment</a>는 Meta AI에서 2023년 5월에 발표한 논문으로, 소규모의 엄선된 instruction dataset 만으로도 pre-training objective와 final objective 사이의 mismatch를 충분한 수준에서 align 할 수 있다는 내용을 다루고 있습니다.</p>
<p>우리의 최종 목표인 ‘LM이 Input으로 주어지는 사람의 지시<em>instruction</em>에 따르게 한다’와 Pre-training 단계의 학습 목표인 ‘Masked&#x2F;Causal Language Modelling의 Loss를 낮춘다’ 사이에는 Mismatch (혹은 Gap)이 존재하고, 이러한 상이한 학습 목표를 어떻게 Align 할 것인가는 최근 NLP 분야에서 많은 관심을 받아온 연구 주제였습니다. 이를테면, ChatGPT의 전신이자 Sibling 모형인 InstructGPT도 해당 문제를 다루고 있고, LLaMA에 Self-Instruct를 활용하여 instruction dataset을 augmentation해서 instruction-tuning을 적용한 Stanford Alpaca도 이러한 Alignment에 관심을 집중하고 있습니다.</p>
<p>아시다시피, ChatGPT의 핵심은 RLHF를 통한 Human Feedback을 학습 과정에 반영하는 것이지만, 해당 프로세스는 꽤 많은 비용을 필요로 합니다. 물론 최대한 자동화된 프로세스를 만들기 위해서 Human Feedback을 예측하는 모형을 만들고, 일정 시점 이후부터는 사람이 직접 LM의 output에 대한 Feedback을 annotation할 필요성이 줄어들긴 하지만, 그럼에도 불구하고 RLHF는 전체적으로 Costly한 과정일 수 밖에 없을 뿐더러, OpenAI는 학습에 사용한 데이터셋을 공개하지 않았기 때문에 데이터&#x2F;모형의 재활용을 통한 비용 절감 또한 기대할 수 없는 상황이죠.</p>
<p>LIMA는 ‘그게… 그렇게까지 할 일인가?’라는 질문에서부터 출발합니다. <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2111.02080">(Xie et al., 2021)</a>과 <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2306.04891">(Ahuja et al., 2023)</a>을 비롯한 여러 논문들의 실험 결과가 암시하듯이, In-context learning ability를 비롯한 LLM의 대부분의 지식은 이미 Pre-training 단계에서 학습된 것이며, instruction-tuning은 단지 사람과 LM이 상호 작용하는 방식을 학습하는 간단한 과정일 수 있습니다. 따라서 ‘RLHF처럼 복잡한 과정 없이도, 엄선된 1k 규모의 instruction dataset만으로도 만족할만한 성능의 alignment를 수행할 수 있다’라는 내용이 LIMA의 저자들이 주장하고자 했던 핵심적인 내용이라고 볼 수 있습니다.</p>
<p>KoLIMA는 LIMA에서 주장하는 내용이 한국어 언어 모형에서도 동일하게 적용되는지 확인해보기 위한 프로젝트입니다. 우선 LIMA dataset을 DeepL API를 활용하여 한국어로 번역한 KoLIMA dataset을 생성하고, 사전 학습된 한국어 언어 모형인 Polyglot-ko을 백본 모형으로 instruction-tuning을 적용하여 모형의 성능을 평가해보고자 합니다. 현재 데이터셋의 번역은 완료된 상태이고, Polyglot-ko 1.3B, 3.8B 모형의 학습에 이어서 5.8B, 12.B 모형의 학습을 진행 중에 있습니다.</p>
<h2 id="This-article-covers"><a href="#This-article-covers" class="headerlink" title="This article covers:"></a>This article covers:</h2><p>이번 글에서는 지금까지 언급했던 내용들인 pre-training, fine-tuning, instruction-tuning, transfer learning 등의 개념을 이해하기 위한 배경 지식에 대해 다룹니다. 이전 글들에서 다루었던 CNNs, RNNs, Transformers 등의 개념이 LM을 구성하는 아키텍쳐 측면에서의 구성 요소였다면, 이번 글에서는 LM을 ‘어떻게 학습시킬 것인가’에 대한 내용을 다룹니다. 다시 말해, 최근 몇 년간의 NLP 분야에서의 연구 트랜드를 Learning Framework의 관점에서 정리해보도록 하겠습니다. 또한, 이 글은 <a target="_blank" rel="noopener" href="https://lena-voita.github.io/nlp_course/transfer_learning.html">Lena Viota</a>와 <a target="_blank" rel="noopener" href="https://www.ruder.io/state-of-transfer-learning-in-nlp/">Sebastian Ruder</a>의 블로그를 참고하고, 많은 영감을 받았음을 미리 밝힙니다.</p>
<h1 id="Learning-Frameworks-in-NLP"><a href="#Learning-Frameworks-in-NLP" class="headerlink" title="Learning Frameworks in NLP"></a>Learning Frameworks in NLP</h1><h2 id="Supervised-Learning-with-Task-specific-Models"><a href="#Supervised-Learning-with-Task-specific-Models" class="headerlink" title="Supervised Learning with Task-specific Models"></a>Supervised Learning with <code>Task-specific Models</code></h2><p>머신러닝을 공부하기 시작하면 가장 먼저 배우게 되는 개념들 중 하나가 바로 지도 학습과 비지도 학습에 대한 내용입니다. 지도 학습은 레이블이 붙어있는 학습 데이터셋을 활용하여 모형이 특정 Task를 수행하는 방법을 가르치는 훈련 방법이죠. 그리고 얼마 전까지만해도 대부분의 NLP Task들은 해당 Task를 수행하기 위한 구체적인 모형이 있고, 해당 모형에 지도 학습 적용하여 훈련시키는 방법을 사용했었습니다. 예를 들어, 텍스트 요약, 주제 분류, 번역과 같은 3개의 구체적인 task가 있다고 할 때, 각각의 task를 위한 세 개의 모형이 별도로 존재하는 형태였죠. 그림으로 표현해보자면 다음과 같습니다</p>
<p>![[Pasted image 20230716173622.png]]</p>
<h2 id="Pre-trained-Models-for-General-Knowledge"><a href="#Pre-trained-Models-for-General-Knowledge" class="headerlink" title="Pre-trained Models for General Knowledge"></a>Pre-trained Models for General Knowledge</h2><p>그런데, 텍스트 요약과, 주제 분류, 번역이라는 세 가지 Task를 잘 하기 위해서 필요한 공통적인 지식이 있을 수 있지 않을까요? 예를 들어, 한국어를 할 줄 모르는 사람에게 한글로된 뉴스 기사를 요약하고, 주제를 분류하고, 영어로 번역하는 것을 가르치는 것보다, 한국어를 이미 알고 있는 사람에게 동일한 내용을 가르치는 것이 훨씬 더 효율적일 것입니다.</p>
<p>![[Pasted image 20230716201512.png]]</p>
<p>이렇게 특정 Task <em>Specific Task</em>에 관계없이 일반적으로 활용될 수 있는 언어에 대한 지식을 일반 지식<em>General Knowledge</em>이라고 하고, 여기에는 개별 단어의 의미, 품사, 문장 내에서의 역할, 문법 구조 등이 포함됩니다. 이러한 일반 지식을 어떤 형태로 개별 모형들에게 전달할 수 있을까요?</p>
<p>가장 일반적인 방법은 단어 임베딩<em>Word Embeddings</em>에 이러한 정보들을 담아 개별 모형의 입력값으로 활용하는 것입니다. 혹은 <a href="https://taes.me/Knowledge%20Integration%20in%20Language%20Model/">지난 글</a>에서 살펴봤던 것처럼 개체 임베딩<em>Entity Embeddings</em>을 활용할 수도 있습니다. 이러한 임베딩을 생성하기 위한 다양한 방법들이 연구되어 왔으며, 대표적으로는 word2vec, ELMo, BERT 등이 있습니다.</p>
<p>각각의 방법론들이 어떤 차이점을 지니고 있는지 Learning Framework의 관점에서 살펴보도록 하겠습니다</p>
<h3 id="word2vec-Static-Word-Embeddings"><a href="#word2vec-Static-Word-Embeddings" class="headerlink" title="word2vec: Static Word Embeddings"></a>word2vec: Static Word Embeddings</h3><p>word2vec은 ‘함께 등장하는 단어 집합이 유사한 단어들은 서로 비슷한 의미를 지닌다’라는 간단한 가정을 기반으로 단어를 수치 벡터로 표현하는 방법입니다. 많은 분들께서 익숙하실 <code>vector(&quot;King&quot;) - vector(&quot;Man&quot;) + vector(&quot;Woman&quot;) = vector(&quot;Queen&quot;)</code>의 예시가 바로 word2vec의 <a target="_blank" rel="noopener" href="https://arxiv.org/abs/1301.3781">original paper</a>에서 처음 등장했습니다. </p>
<p>![[Pasted image 20230716222738.png]]</p>
<p>다만 word2vec은 주변에 함께 등장한 단어를 고려하지 못하고 하나의 단어에 고정된 하나의 임베딩만을 할당한다는 단점이 있습니다. 다시 말해, word2vec을 통해 생성한 임베딩을 통해서는 <a href="https://taes.me/Dependency%20in%20Languages/">이 글</a>에서 다루었던 여러 의미를 지닐 수 있는 ‘배’를 각각 다르게 표현할 수 없으며, 이러한 형태의 embedding을 우리는 static embedding 이라고 부릅니다.</p>
<h3 id="ELMo-Contextualised-Word-Embeddings"><a href="#ELMo-Contextualised-Word-Embeddings" class="headerlink" title="ELMo: Contextualised Word Embeddings"></a>ELMo: Contextualised Word Embeddings</h3><p>(아래에서 언급될 BERT와 동일하게) ELMo는 이러한 static embedding의 단점을 개선한 contextualised embedding을 생성하는 방법론입니다. 아래의 예시에서, static embedding이 단어 ‘cat’의 의미를 flying cat이든 the cat on the mat의 cat이든, the cat by the door의 cat이든 동일하게 표현할 수 밖에 없는 데에 반해, ELMo를 비롯한 Contextualised Embedding 기법들에서는 각각의 cat을 주변 맥락<em>Context</em>를 고려한 임베딩으로 나타낼 수 있습니다.</p>
<p>![[Pasted image 20230716223431.png]]<br>(Figure from Lena Voita)</p>
<p>지금까지 살펴본 것처럼 word2vec과 ELMo는 단어를 표현할 때 주변 맥락을 고려할 수 있는지 없는지에 따른 차이가 있긴 하지만, 모형에서 활용되는 방법에 있어서는 차이가 없습니다. 다시 말해, 아래의 그림에서 살펴볼 수 있는 것처럼 각각의 pre-trained model은 단어 집합을 입력으로 받아 각각의 단어에 대한 pre-trained embeddings을 생성하고, 이를 다시 task-specific한 모형에 전달하는 형태로 전체 모형에서 활용되게 됩니다.</p>
<p>![[Pasted image 20230716223735.png]]</p>
<h3 id="BERT-Single-Model-for-ALL-NLP-Tasks-with-Contextualised-Word-Embeddings"><a href="#BERT-Single-Model-for-ALL-NLP-Tasks-with-Contextualised-Word-Embeddings" class="headerlink" title="BERT: Single Model for ALL NLP Tasks with Contextualised Word Embeddings"></a>BERT: Single Model for ALL NLP Tasks with Contextualised Word Embeddings</h3><p>반면 BERT는 다양한 Downstream Task에 대한 접근법이 다소 다릅니다. 여러 종류의 task-specific model이 별도로 존재하고, general knowledge는 pre-trained model로부터 생성된 embedding을 통해 개별 모형에 전달되던 기존 구조와 달리, BERT는 모든 downstream task를 BERT 하나만으로 수행해도 기존 개별 모형 대비 더 높은 성능을 달성할 수 있다는 사실을 보였습니다. </p>
<p>![[Pasted image 20230716224255.png]]</p>
<h1 id="Outro"><a href="#Outro" class="headerlink" title="Outro"></a>Outro</h1><p>이번 글에서는 Sequential Transfer Learning의 기본적인 개념인 Pre-training과 Fine-tuning에 대해 살펴보았습니다. 다음 글에서는 In-context Learning, Prompting, Few&#x2F;Zero-shot Learning, Instruction-tuning의 개념에 대해 살펴보도록 하겠습니다.</p>
</div><div class="article-licensing box"><div class="licensing-title"><p>Learning Frameworks in NLP (1/2)</p><p><a href="https://taes.me/LF-NLP-1/">https://taes.me/LF-NLP-1/</a></p></div><div class="licensing-meta level is-mobile"><div class="level-left"><div class="level-item is-narrow"><div><h6>Author</h6><p>Taeseung Hahn</p></div></div><div class="level-item is-narrow"><div><h6>Posted on</h6><p>2023-07-16</p></div></div><div class="level-item is-narrow"><div><h6>Updated on</h6><p>2023-07-16</p></div></div><div class="level-item is-narrow"><div><h6>Licensed under</h6><p><a class="icons" rel="noopener" target="_blank" title="Creative Commons" href="https://creativecommons.org/"><i class="icon fab fa-creative-commons"></i></a><a class="icons" rel="noopener" target="_blank" title="Attribution" href="https://creativecommons.org/licenses/by/4.0/"><i class="icon fab fa-creative-commons-by"></i></a><a class="icons" rel="noopener" target="_blank" title="Noncommercial" href="https://creativecommons.org/licenses/by-nc/4.0/"><i class="icon fab fa-creative-commons-nc"></i></a></p></div></div></div></div></div><div class="article-tags is-size-7 mb-4"><span class="mr-2">#</span><a class="link-muted mr-2" rel="tag" href="/tags/NLP/">NLP</a></div><div class="sharethis-inline-share-buttons"></div><script src="https://platform-api.sharethis.com/js/sharethis.js#property=62811fe0d1ad83001a8b9206&amp;product=inline-share-buttons" defer></script></article></div><!--!--><nav class="post-navigation mt-4 level is-mobile"><div class="level-end"><a class="article-nav-next level level-item link-muted" href="/Dependency%20in%20Languages/"><i class="level-item fas fa-chevron-left"></i><span class="level-item">Dependency in Language</span></a></div></nav><div class="card"><div class="card-content"><h3 class="title is-5">Comments</h3><script src="https://utteranc.es/client.js" repo="taeshahn/PagesUtterances" issue-term="pathname" label="comment" crossorigin="anonymous" async></script></div></div></div><div class="column column-left is-3-tablet is-3-desktop is-3-widescreen  order-1"><div class="card widget" id="toc" data-type="toc"><div class="card-content"><div class="menu"><h3 class="menu-label">Catalogue</h3><ul class="menu-list"><li><a class="level is-mobile" href="#Intro"><span class="level-left"><span class="level-item">1</span><span class="level-item">Intro</span></span></a><ul class="menu-list"><li><a class="level is-mobile" href="#LIMA-and-KoLIMA"><span class="level-left"><span class="level-item">1.1</span><span class="level-item">LIMA and KoLIMA</span></span></a></li><li><a class="level is-mobile" href="#This-article-covers"><span class="level-left"><span class="level-item">1.2</span><span class="level-item">This article covers:</span></span></a></li></ul></li><li><a class="level is-mobile" href="#Learning-Frameworks-in-NLP"><span class="level-left"><span class="level-item">2</span><span class="level-item">Learning Frameworks in NLP</span></span></a><ul class="menu-list"><li><a class="level is-mobile" href="#Supervised-Learning-with-Task-specific-Models"><span class="level-left"><span class="level-item">2.1</span><span class="level-item">Supervised Learning with Task-specific Models</span></span></a></li><li><a class="level is-mobile" href="#Pre-trained-Models-for-General-Knowledge"><span class="level-left"><span class="level-item">2.2</span><span class="level-item">Pre-trained Models for General Knowledge</span></span></a><ul class="menu-list"><li><a class="level is-mobile" href="#word2vec-Static-Word-Embeddings"><span class="level-left"><span class="level-item">2.2.1</span><span class="level-item">word2vec: Static Word Embeddings</span></span></a></li><li><a class="level is-mobile" href="#ELMo-Contextualised-Word-Embeddings"><span class="level-left"><span class="level-item">2.2.2</span><span class="level-item">ELMo: Contextualised Word Embeddings</span></span></a></li><li><a class="level is-mobile" href="#BERT-Single-Model-for-ALL-NLP-Tasks-with-Contextualised-Word-Embeddings"><span class="level-left"><span class="level-item">2.2.3</span><span class="level-item">BERT: Single Model for ALL NLP Tasks with Contextualised Word Embeddings</span></span></a></li></ul></li></ul></li><li><a class="level is-mobile" href="#Outro"><span class="level-left"><span class="level-item">3</span><span class="level-item">Outro</span></span></a></li></ul></div></div><script src="/js/toc.js" defer></script></div><div class="card widget" data-type="categories"><div class="card-content"><div class="menu"><h3 class="menu-label">Categories</h3><ul class="menu-list"><li><a class="level is-mobile" href="/categories/Information-Theory/"><span class="level-start"><span class="level-item">Information Theory</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/NLP/"><span class="level-start"><span class="level-item">NLP</span></span><span class="level-end"><span class="level-item tag">3</span></span></a></li><li><a class="level is-mobile" href="/categories/Others/"><span class="level-start"><span class="level-item">Others</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/categories/R/"><span class="level-start"><span class="level-item">R</span></span><span class="level-end"><span class="level-item tag">3</span></span></a></li><li><a class="level is-mobile" href="/categories/WeeklyNLP/"><span class="level-start"><span class="level-item">WeeklyNLP</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li></ul></div></div></div><div class="card widget" data-type="recent-posts"><div class="card-content"><h3 class="menu-label">Recents</h3><article class="media"><div class="media-content"><p class="date"><time dateTime="2023-07-16T00:00:00.000Z">2023-07-16</time></p><p class="title"><a href="/LF-NLP-1/">Learning Frameworks in NLP (1/2)</a></p><p class="categories"><a href="/categories/NLP/">NLP</a></p></div></article><article class="media"><div class="media-content"><p class="date"><time dateTime="2023-07-02T00:00:00.000Z">2023-07-02</time></p><p class="title"><a href="/Dependency%20in%20Languages/">Dependency in Language</a></p></div></article><article class="media"><div class="media-content"><p class="date"><time dateTime="2023-04-23T00:00:00.000Z">2023-04-23</time></p><p class="title"><a href="/Knowledge%20Integration%20in%20Language%20Model/">Knowledge Integration in Language Models</a></p><p class="categories"><a href="/categories/NLP/">NLP</a></p></div></article><article class="media"><div class="media-content"><p class="date"><time dateTime="2023-02-01T00:00:00.000Z">2023-02-01</time></p><p class="title"><a href="/Language%20Models/">Language Models</a></p><p class="categories"><a href="/categories/WeeklyNLP/">WeeklyNLP</a></p></div></article><article class="media"><div class="media-content"><p class="date"><time dateTime="2022-02-28T00:00:00.000Z">2022-02-28</time></p><p class="title"><a href="/Weekly-NLP-Intro/">Weekly-NLP, Introduction</a></p><p class="categories"><a href="/categories/NLP/">NLP</a></p></div></article></div></div></div><!--!--></div></div></section><footer class="footer"><div class="container"><div class="level"><div class="level-start"><a class="footer-logo is-block mb-2" href="/"><img src="/img/ts_logo.png" alt="Taeseung Hahn" height="28"></a><p class="is-size-7"><span>&copy; 2023 Taeseung Hahn</span>  Powered by <a href="https://hexo.io/" target="_blank" rel="noopener">Hexo</a> &amp; <a href="https://github.com/ppoffice/hexo-theme-icarus" target="_blank" rel="noopener">Icarus</a></p></div><div class="level-end"><div class="field has-addons"><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Creative Commons" href="https://creativecommons.org/"><i class="fab fa-creative-commons"></i></a></p><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Attribution 4.0 International" href="https://creativecommons.org/licenses/by/4.0/"><i class="fab fa-creative-commons-by"></i></a></p><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Download on GitHub" href="https://github.com/ppoffice/hexo-theme-icarus"><i class="fab fa-github"></i></a></p></div></div></div></div></footer><script src="https://cdn.jsdelivr.net/npm/jquery@3.3.1/dist/jquery.min.js"></script><script src="https://cdn.jsdelivr.net/npm/moment@2.22.2/min/moment-with-locales.min.js"></script><script src="https://cdn.jsdelivr.net/npm/clipboard@2.0.4/dist/clipboard.min.js" defer></script><script>moment.locale("en");</script><script>var IcarusThemeSettings = {
            article: {
                highlight: {
                    clipboard: true,
                    fold: 'unfolded'
                }
            }
        };</script><script src="/js/column.js"></script><script src="/js/animation.js"></script><a id="back-to-top" title="Back to top" href="javascript:;"><i class="fas fa-chevron-up"></i></a><script src="/js/back_to_top.js" defer></script><!--!--><!--!--><!--!--><script src="https://cdn.jsdelivr.net/npm/cookieconsent@3.1.1/build/cookieconsent.min.js" defer></script><script>window.addEventListener("load", () => {
      window.cookieconsent.initialise({
        type: "info",
        theme: "edgeless",
        static: false,
        position: "bottom-left",
        content: {
          message: "This website uses cookies to improve your experience.",
          dismiss: "Got it!",
          allow: "Allow cookies",
          deny: "Decline",
          link: "Learn more",
          policy: "Cookie Policy",
          href: "https://www.cookiesandyou.com/",
        },
        palette: {
          popup: {
            background: "#edeff5",
            text: "#838391"
          },
          button: {
            background: "#4b81e8"
          },
        },
      });
    });</script><script src="https://cdn.jsdelivr.net/npm/lightgallery@1.10.0/dist/js/lightgallery.min.js" defer></script><script src="https://cdn.jsdelivr.net/npm/justifiedGallery@3.8.1/dist/js/jquery.justifiedGallery.min.js" defer></script><script>window.addEventListener("load", () => {
            if (typeof $.fn.lightGallery === 'function') {
                $('.article').lightGallery({ selector: '.gallery-item' });
            }
            if (typeof $.fn.justifiedGallery === 'function') {
                if ($('.justified-gallery > p > .gallery-item').length) {
                    $('.justified-gallery > p > .gallery-item').unwrap();
                }
                $('.justified-gallery').justifiedGallery();
            }
        });</script><!--!--><!--!--><script type="text/x-mathjax-config">MathJax.Hub.Config({
            'HTML-CSS': {
                matchFontHeight: false
            },
            SVG: {
                matchFontHeight: false
            },
            CommonHTML: {
                matchFontHeight: false
            },
            tex2jax: {
                inlineMath: [
                    ['$','$'],
                    ['\\(','\\)']
                ]
            }
        });</script><script src="https://cdn.jsdelivr.net/npm/mathjax@2.7.9/unpacked/MathJax.js?config=TeX-MML-AM_CHTML" defer></script><!--!--><!--!--><!--!--><script src="/js/main.js" defer></script><div class="searchbox"><div class="searchbox-container"><div class="searchbox-header"><div class="searchbox-input-container"><input class="searchbox-input" type="text" placeholder="Type something..."></div><a class="searchbox-close" href="javascript:;">×</a></div><div class="searchbox-body"></div></div></div><script src="/js/insight.js" defer></script><script>document.addEventListener('DOMContentLoaded', function () {
            loadInsight({"contentUrl":"/content.json"}, {"hint":"Type something...","untitled":"(Untitled)","posts":"Posts","pages":"Pages","categories":"Categories","tags":"Tags"});
        });</script></body></html>